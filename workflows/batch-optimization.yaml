apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: batch-optimization
  namespace: cogniverse
spec:
  entrypoint: optimization-pipeline

  arguments:
    parameters:
    - name: tenant-id
      value: "default"
    - name: optimizer-category
      value: "dspy"  # dspy, routing
    - name: optimizer-type
      value: "GEPA"  # DSPy: GEPA, Bootstrap, SIMBA, MIPRO | Routing: modality, cross_modal, routing, workflow, unified
    - name: dataset-name
      value: "golden_eval_v1"
    - name: profiles
      value: "video_colpali_smol500_mv_frame"
    - name: max-iterations
      value: "100"
    - name: learning-rate
      value: "0.001"
    - name: use-synthetic-data
      value: "false"  # Generate synthetic data or use dataset

  templates:
  # Main optimization pipeline
  - name: optimization-pipeline
    steps:
    - - name: validate-config
        template: validate-config
    - - name: prepare-dataset
        template: prepare-dataset
    - - name: run-optimization
        template: run-optimization
    - - name: evaluate-results
        template: evaluate-results
    - - name: deploy-optimized-model
        template: deploy-optimized-model
        when: "{{steps.evaluate-results.outputs.parameters.improvement}} > 5"
    - - name: notify-completion
        template: notify-completion

  # Validate optimization configuration
  - name: validate-config
    container:
      image: cogniverse/runtime:2.0.0
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e
          echo "Validating optimization configuration..."
          echo "Category: {{workflow.parameters.optimizer-category}}"
          echo "Type: {{workflow.parameters.optimizer-type}}"

          # Validate optimizer category and type
          CATEGORY="{{workflow.parameters.optimizer-category}}"
          TYPE="{{workflow.parameters.optimizer-type}}"

          if [ "$CATEGORY" == "dspy" ]; then
            VALID_OPTIMIZERS="GEPA Bootstrap SIMBA MIPRO"
            if ! echo "$VALID_OPTIMIZERS" | grep -q "$TYPE"; then
              echo "ERROR: Invalid DSPy optimizer type: $TYPE"
              exit 1
            fi

            # Check dataset exists for DSPy
            DATASET_PATH="/app/data/testset/evaluation/{{workflow.parameters.dataset-name}}.csv"
            if [ "{{workflow.parameters.use-synthetic-data}}" == "false" ] && [ ! -f "$DATASET_PATH" ]; then
              echo "ERROR: Dataset not found: $DATASET_PATH"
              exit 1
            fi
          elif [ "$CATEGORY" == "routing" ]; then
            VALID_OPTIMIZERS="modality cross_modal routing workflow unified"
            if ! echo "$VALID_OPTIMIZERS" | grep -q "$TYPE"; then
              echo "ERROR: Invalid routing optimizer type: $TYPE"
              exit 1
            fi
          else
            echo "ERROR: Invalid optimizer category: $CATEGORY"
            exit 1
          fi

          echo "Configuration valid"
      resources:
        requests:
          memory: "512Mi"
          cpu: "500m"
        limits:
          memory: "1Gi"
          cpu: "1"

  # Prepare evaluation dataset
  - name: prepare-dataset
    container:
      image: cogniverse/runtime:2.0.0
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e
          echo "Preparing evaluation dataset..."

          # Load and validate dataset
          cd /app
          uv run python -c "
          import pandas as pd
          df = pd.read_csv('data/testset/evaluation/{{workflow.parameters.dataset-name}}.csv')
          print(f'Dataset loaded: {len(df)} samples')
          print(f'Columns: {df.columns.tolist()}')
          "

          echo "Dataset prepared"
      env:
      - name: TENANT_ID
        value: "{{workflow.parameters.tenant-id}}"
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"

  # Run optimization (supports both DSPy and routing optimizers)
  - name: run-optimization
    container:
      image: cogniverse/runtime:2.0.0
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e
          echo "Running {{workflow.parameters.optimizer-category}} optimization..."
          echo "Optimizer type: {{workflow.parameters.optimizer-type}}"
          echo "Tenant: {{workflow.parameters.tenant-id}}"

          cd /app

          # Generate synthetic data if requested
          if [ "{{workflow.parameters.use-synthetic-data}}" == "true" ] && [ "{{workflow.parameters.optimizer-category}}" == "routing" ]; then
            echo "Generating synthetic training data..."
            JAX_PLATFORM_NAME=cpu uv run python -c "
          import requests
          import json

          response = requests.post(
              'http://cogniverse-runtime:8000/synthetic/generate',
              json={
                  'optimizer': '{{workflow.parameters.optimizer-type}}',
                  'count': 200,
                  'vespa_sample_size': 500,
                  'strategies': ['diverse', 'entity_rich'],
                  'max_profiles': 3,
                  'tenant_id': '{{workflow.parameters.tenant-id}}'
              },
              timeout=300
          )

          if response.status_code == 200:
              result = response.json()
              print(f'Generated {result[\"count\"]} synthetic examples')
              with open('/tmp/synthetic_data.json', 'w') as f:
                  json.dump(result, f)
          else:
              print(f'Synthetic data generation failed: {response.status_code}')
              exit(1)
          "
          fi

          # Run optimizer based on category
          if [ "{{workflow.parameters.optimizer-category}}" == "dspy" ]; then
            echo "Running DSPy optimizer..."
            JAX_PLATFORM_NAME=cpu uv run python scripts/run_optimization.py \
              --tenant-id {{workflow.parameters.tenant-id}} \
              --optimizer {{workflow.parameters.optimizer-type}} \
              --dataset {{workflow.parameters.dataset-name}} \
              --profiles {{workflow.parameters.profiles}} \
              --max-iterations {{workflow.parameters.max-iterations}} \
              --learning-rate {{workflow.parameters.learning-rate}} \
              --output /tmp/optimization_results.json

          elif [ "{{workflow.parameters.optimizer-category}}" == "routing" ]; then
            echo "Running module optimizer..."

            # Determine if we should use synthetic data
            USE_SYNTHETIC_FLAG=""
            if [ "{{workflow.parameters.use-synthetic-data}}" == "true" ]; then
              USE_SYNTHETIC_FLAG="--use-synthetic-data"
            fi

            JAX_PLATFORM_NAME=cpu uv run python scripts/run_module_optimization.py \
              --module {{workflow.parameters.optimizer-type}} \
              --tenant-id {{workflow.parameters.tenant-id}} \
              $USE_SYNTHETIC_FLAG \
              --max-iterations {{workflow.parameters.max-iterations}} \
              --output /tmp/optimization_results.json
          else
            echo "ERROR: Unknown optimizer category: {{workflow.parameters.optimizer-category}}"
            exit 1
          fi

          # Check results
          if [ ! -f /tmp/optimization_results.json ]; then
            echo "ERROR: Optimization results not generated"
            exit 1
          fi

          # Extract metrics (handle different result formats)
          BASELINE_SCORE=$(cat /tmp/optimization_results.json | python3 -c "
          import sys, json
          r = json.load(sys.stdin)
          print(r.get('baseline_score', r.get('baseline_accuracy', 0)))
          ")

          OPTIMIZED_SCORE=$(cat /tmp/optimization_results.json | python3 -c "
          import sys, json
          r = json.load(sys.stdin)
          print(r.get('optimized_score', r.get('optimized_accuracy', 0)))
          ")

          IMPROVEMENT=$(echo "scale=2; ($OPTIMIZED_SCORE - $BASELINE_SCORE) / $BASELINE_SCORE * 100" | bc)

          echo "Baseline score: $BASELINE_SCORE"
          echo "Optimized score: $OPTIMIZED_SCORE"
          echo "Improvement: ${IMPROVEMENT}%"

          # Save metrics
          echo "$BASELINE_SCORE" > /tmp/baseline_score.txt
          echo "$OPTIMIZED_SCORE" > /tmp/optimized_score.txt
          echo "$IMPROVEMENT" > /tmp/improvement.txt

          echo "Optimization completed"
      env:
      - name: VESPA_URL
        value: "http://cogniverse-vespa:8080"
      - name: PHOENIX_ENDPOINT
        value: "http://cogniverse-phoenix:6006"
      - name: TENANT_ID
        value: "{{workflow.parameters.tenant-id}}"
      - name: LLM_MODEL
        value: "ollama/mistral:7b-instruct"
      - name: OLLAMA_ENDPOINT
        value: "http://cogniverse-ollama:11434"
      resources:
        requests:
          memory: "16Gi"
          cpu: "8"
        limits:
          memory: "32Gi"
          cpu: "16"
      # Add GPU if available
      # nvidia.com/gpu: "1"
    outputs:
      parameters:
      - name: baseline-score
        valueFrom:
          path: /tmp/baseline_score.txt
      - name: optimized-score
        valueFrom:
          path: /tmp/optimized_score.txt
      - name: improvement
        valueFrom:
          path: /tmp/improvement.txt

  # Evaluate optimization results
  - name: evaluate-results
    container:
      image: cogniverse/runtime:2.0.0
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e
          echo "Evaluating optimization results..."

          IMPROVEMENT="{{steps.run-optimization.outputs.parameters.improvement}}"
          echo "Improvement: ${IMPROVEMENT}%"

          # Check if improvement meets threshold
          if (( $(echo "$IMPROVEMENT > 5" | bc -l) )); then
            echo "Improvement exceeds threshold (5%)"
            echo "Recommendation: Deploy optimized model"
          else
            echo "Improvement below threshold (5%)"
            echo "Recommendation: Keep current model"
          fi

          echo "Evaluation completed"
      resources:
        requests:
          memory: "1Gi"
          cpu: "1"
        limits:
          memory: "2Gi"
          cpu: "2"
    outputs:
      parameters:
      - name: improvement
        value: "{{steps.run-optimization.outputs.parameters.improvement}}"

  # Deploy optimized model
  - name: deploy-optimized-model
    container:
      image: cogniverse/runtime:2.0.0
      command: ["/bin/bash", "-c"]
      args:
        - |
          set -e
          echo "Deploying optimized model..."

          # Save optimized routing model
          cd /app
          uv run python -c "
          import json
          from cogniverse_agents.routing.optimization_orchestrator import OptimizationOrchestrator

          # Load optimized parameters
          with open('/tmp/optimization_results.json', 'r') as f:
              results = json.load(f)

          # Deploy to production
          print('Deploying optimized routing model...')
          # Add deployment logic here
          print('Deployment completed')
          "

          echo "Model deployed successfully"
      env:
      - name: TENANT_ID
        value: "{{workflow.parameters.tenant-id}}"
      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"

  # Send completion notification
  - name: notify-completion
    container:
      image: curlimages/curl:latest
      command: ["/bin/sh", "-c"]
      args:
        - |
          echo "Optimization workflow completed"
          echo "Tenant: {{workflow.parameters.tenant-id}}"
          echo "Optimizer: {{workflow.parameters.optimizer-type}}"
          echo "Baseline: {{steps.run-optimization.outputs.parameters.baseline-score}}"
          echo "Optimized: {{steps.run-optimization.outputs.parameters.optimized-score}}"
          echo "Improvement: {{steps.run-optimization.outputs.parameters.improvement}}%"

          # Send notification
          # curl -X POST https://your-webhook-url \
          #   -H "Content-Type: application/json" \
          #   -d '{
          #     "workflow": "batch-optimization",
          #     "tenant": "{{workflow.parameters.tenant-id}}",
          #     "improvement": "{{steps.run-optimization.outputs.parameters.improvement}}",
          #     "status": "completed"
          #   }'
      resources:
        requests:
          memory: "128Mi"
          cpu: "100m"
        limits:
          memory: "256Mi"
          cpu: "200m"
---
# Example Workflow submission
apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: batch-optimization-
  namespace: cogniverse
spec:
  workflowTemplateRef:
    name: batch-optimization
  arguments:
    parameters:
    - name: tenant-id
      value: "acme_corp"
    - name: optimizer-type
      value: "GEPA"
    - name: dataset-name
      value: "golden_eval_v1"
    - name: profiles
      value: "video_colpali_smol500_mv_frame"
    - name: max-iterations
      value: "200"
    - name: learning-rate
      value: "0.001"
