[pytest]
# Evaluation-specific test configuration
testpaths = .
python_files = test_*.py
python_classes = Test*
python_functions = test_*

# Evaluation-specific markers
markers =
    unit: Unit tests for individual components
    integration: Integration tests with multiple components
    slow: Slow tests that take significant time
    phoenix: Tests requiring Phoenix
    inspect: Tests requiring Inspect AI
    ragas: Tests requiring RAGAS
    requires_models: Tests that require actual ML models to be available
    benchmark: Performance benchmarking tests
    local_only: Tests that should only run locally (not in CI/CD)
    ci_safe: Tests that are safe to run in CI environment

# Evaluation-only test configuration (coverage handled by Makefile)
addopts = 
    -ra
    -v
    --tb=short
    --strict-markers

# Filter warnings
filterwarnings =
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning

[coverage:run]
source = src/evaluation
omit = 
    */tests/*
    */conftest.py

[coverage:report]
exclude_lines =
    pragma: no cover
    def __repr__
    raise AssertionError
    raise NotImplementedError
    if __name__ == .__main__.